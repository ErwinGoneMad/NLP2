{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 0: Le Sandbox Poétique\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Chargement du modèle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llama_context: n_ctx_per_seq (2048) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "from llama_cpp import Llama\n",
        "\n",
        "# Chemin vers le modèle téléchargé\n",
        "MODEL_PATH = \"./models/Llama-3.2-1B-Instruct.Q4_K_M.gguf\"\n",
        "\n",
        "# Vérifier que le modèle existe\n",
        "if not Path(MODEL_PATH).exists():\n",
        "    print(f\"erreur: Le modèle n'a pas été trouvé à {MODEL_PATH}\")\n",
        "    print(\"run python download_model.py\")\n",
        "    sys.exit(1)\n",
        "\n",
        "\n",
        "# n_ctx=2048 signifie que le modèle peut se souvenir d'environ 1500 mots de conversation\n",
        "llm = Llama(\n",
        "    model_path=MODEL_PATH,\n",
        "    n_ctx=2048,\n",
        "    verbose=False  # True : voir les statistiques de vitesse\n",
        ")\n",
        "\n",
        "print(\"done\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Sandbox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Génération d'un sonnet sur 'le silence de l'hiver' ---\n",
            "\n",
            "In le silence de l'hiver, les branches sont froisses,\n",
            "Les feuilles se sont éteintes, comme des larmes,\n",
            "Les arbres, qui ont chanté tout l'an,\n",
            "Se courent, comme des souvenirs qui s'entretiennent.\n",
            "\n",
            "Le vent souffle, un murmure doux et larme,\n",
            "Les glaçons qui tombent de l'atmosphère,\n",
            "Un mélange de glace et de mouchoir de larme,\n",
            "Qui fait trembler les arbres, comme des éclairs de l'air.\n",
            "\n",
            "Mais dans cette fin de hiver, je trouve un charme,\n",
            "Un silence profond, qui me fait se lancer,\n",
            "Vers les souvenirs, vers les souvenirs de la garde,\n",
            "Vers les bois qui font chouer, les bois qui font chanter.\n",
            "\n",
            "Et puis, dans ce silence, je trouve une paix,\n",
            "Une paix qui me fait oublier mes souvenirs, ma grâce.\n",
            "\n",
            "(Note: I've tried to follow the traditional sonnet structure and rhyme scheme, but I want to acknowledge that \"le silence de l'hiver\" is a bit of a challenging topic for a sonnet, as it's more of a poetic description than a traditional narrative. If you'd like, I can try to write a more traditional sonnet about it.)\n"
          ]
        }
      ],
      "source": [
        "TOPIC = \"le silence de l'hiver\"\n",
        "FORM = \"sonnet\"  # \"sonnet\", \"limerick\", \"poème en vers libres\"\n",
        "\n",
        "prompt_structure = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a skilled poet.\"},\n",
        "    {\"role\": \"user\", \"content\": f\"Write a {FORM} about {TOPIC} in french.\"}\n",
        "]\n",
        "\n",
        "print(f\"\\n--- Génération d'un {FORM} sur '{TOPIC}' ---\\n\")\n",
        "\n",
        "output = llm.create_chat_completion(\n",
        "    messages=prompt_structure,\n",
        "    max_tokens=1000,   \n",
        "    temperature=0.8,\n",
        "    top_p=0.95,\n",
        ")\n",
        "\n",
        "poem = output[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "print(poem)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sauvegarder le poème \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "544"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "output_file = Path(\"poem.txt\")\n",
        "output_file.write_text(poem, encoding=\"utf-8\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Implémentation du graphe thématique et de la fonction graph_to_prompt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Prompt structuré généré ===\n",
            "\n",
            "You will write a 14-line sonnet in French.\n",
            "Follow this structured plan for each section:\n",
            "\n",
            "Lines 1-3: Focus on 'deuil' imagery and emotions.\n",
            "Lines 4-6: Focus on 'mémoire' imagery and emotions.\n",
            "Lines 7-8: Focus on 'océan' imagery and emotions.\n",
            "Lines 9-10: Transition from 'deuil' to 'mémoire'.\n",
            "Lines 11-12: Transition from 'mémoire' to 'océan'.\n",
            "Lines 13-14: Synthesize all themes (deuil, mémoire, océan) in a concluding reflection.\n"
          ]
        }
      ],
      "source": [
        "def graph_to_prompt(graph, form_spec):\n",
        "    \"\"\"\n",
        "    Transforme un graphe thématique en prompt structuré pour la génération poétique.\n",
        "    \n",
        "    Args:\n",
        "        graph: dict avec \"nodes\" (list) et \"edges\" (list de tuples)\n",
        "        form_spec: dict avec \"form\" (str) et \"total_lines\" (int)\n",
        "    \n",
        "    Returns:\n",
        "        str: prompt structuré détaillant le plan de chaque section\n",
        "    \"\"\"\n",
        "    nodes = graph[\"nodes\"]\n",
        "    edges = graph[\"edges\"]\n",
        "    form = form_spec[\"form\"]\n",
        "    total_lines = form_spec[\"total_lines\"]\n",
        "    \n",
        "    # Calculer la distribution des lignes\n",
        "    num_sections = len(nodes) + len(edges) + 1  # sections pour chaque noeud, chaque transition, + synthèse\n",
        "    lines_per_section = total_lines // num_sections\n",
        "    remainder = total_lines % num_sections\n",
        "    \n",
        "    prompt_parts = [\n",
        "        f\"You will write a {total_lines}-line {form} in French.\",\n",
        "        \"Follow this structured plan for each section:\",\n",
        "        \"\"\n",
        "    ]\n",
        "    \n",
        "    line_num = 1\n",
        "    \n",
        "    # Section pour chaque noeud initial\n",
        "    for i, node in enumerate(nodes):\n",
        "        end_line = line_num + lines_per_section - 1\n",
        "        if i < remainder:\n",
        "            end_line += 1\n",
        "        prompt_parts.append(f\"Lines {line_num}-{end_line}: Focus on '{node}' imagery and emotions.\")\n",
        "        line_num = end_line + 1\n",
        "    \n",
        "    # Sections pour les transitions (edges)\n",
        "    for i, (source, target) in enumerate(edges):\n",
        "        end_line = line_num + lines_per_section - 1\n",
        "        if len(nodes) + i < remainder:\n",
        "            end_line += 1\n",
        "        prompt_parts.append(f\"Lines {line_num}-{end_line}: Transition from '{source}' to '{target}'.\")\n",
        "        line_num = end_line + 1\n",
        "    \n",
        "    # Section de synthèse finale\n",
        "    if line_num <= total_lines:\n",
        "        remaining_lines = total_lines - line_num + 1\n",
        "        all_nodes = \", \".join(nodes)\n",
        "        prompt_parts.append(f\"Lines {line_num}-{total_lines}: Synthesize all themes ({all_nodes}) in a concluding reflection.\")\n",
        "    \n",
        "    return \"\\n\".join(prompt_parts)\n",
        "\n",
        "# Exemple de graphe thématique\n",
        "example_graph = {\n",
        "    \"nodes\": [\"deuil\", \"mémoire\", \"océan\"],\n",
        "    \"edges\": [(\"deuil\", \"mémoire\"), (\"mémoire\", \"océan\")]\n",
        "}\n",
        "\n",
        "# Spécification pour un sonnet (14 lignes)\n",
        "sonnet_spec = {\n",
        "    \"form\": \"sonnet\",\n",
        "    \"total_lines\": 14\n",
        "}\n",
        "\n",
        "# Générer le prompt structuré\n",
        "structured_prompt = graph_to_prompt(example_graph, sonnet_spec)\n",
        "print(\"=== Prompt structuré généré ===\\n\")\n",
        "print(structured_prompt)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Génération avec le graphe thématique\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Génération avec graphe thématique ===\n",
            "\n",
            "Instructions structurées:\n",
            "You will write a 14-line sonnet in French.\n",
            "Follow this structured plan for each section:\n",
            "\n",
            "Lines 1-3: Focus on 'deuil' imagery and emotions.\n",
            "Lines 4-6: Focus on 'mémoire' imagery and emotions.\n",
            "Lines 7-8: Focus on 'océan' imagery and emotions.\n",
            "Lines 9-10: Transition from 'deuil' to 'mémoire'.\n",
            "Lines 11-12: Transition from 'mémoire' to 'océan'.\n",
            "Lines 13-14: Synthesize all themes (deuil, mémoire, océan) in a concluding reflection.\n",
            "\n",
            "==================================================\n",
            "\n",
            "Dans l'ombre sombre où deuil éclate\n",
            "Les souvenirs se répandent comme des feuilles\n",
            "Froides et éphémères qui brûlent dans la mémoire\n",
            "Comme des rêves qui disparaissent dans l'océan\n",
            "\n",
            "Les ténèbres me recueillent comme des oiseaux\n",
            "Qui retournent vers leurs ailes mortes, sans voix\n",
            "Les étoiles éclatent dans l'espace sombre comme des éclairs\n",
            "Comme des larmes qui ne peuvent plus pleurer dans l'océan\n",
            "\n",
            "Le temps me frappe comme un tonnerre\n",
            "Qui me fait trembler sous le poids de mes souvenirs\n",
            "Les vagues de la mémoire me dépassent dans l'océan\n",
            "Comme des navires qui se perdent au large dans la mer\n",
            "\n",
            "Mais dans le fond de l'eau, un esprit m'éprouve\n",
            "Un rêve qui me montre que je suis encore vivant.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "TOPIC_GRAPH = {\n",
        "    \"nodes\": [\"deuil\", \"mémoire\", \"océan\"],\n",
        "    \"edges\": [(\"deuil\", \"mémoire\"), (\"mémoire\", \"océan\")]\n",
        "}\n",
        "\n",
        "FORM_SPEC = {\n",
        "    \"form\": \"sonnet\",\n",
        "    \"total_lines\": 14\n",
        "}\n",
        "\n",
        "\n",
        "structured_instructions = graph_to_prompt(TOPIC_GRAPH, FORM_SPEC)\n",
        "\n",
        "prompt_with_graph = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a skilled poet. Write in French.\"},\n",
        "    {\"role\": \"user\", \"content\": structured_instructions}\n",
        "]\n",
        "\n",
        "print(\"=== Génération avec graphe thématique ===\\n\")\n",
        "print(\"Instructions structurées:\")\n",
        "print(structured_instructions)\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "output_graph = llm.create_chat_completion(\n",
        "    messages=prompt_with_graph,\n",
        "    max_tokens=1000,\n",
        "    temperature=0.8,\n",
        "    top_p=0.95,\n",
        ")\n",
        "\n",
        "poem_with_graph = output_graph[\"choices\"][0][\"message\"][\"content\"]\n",
        "print(poem_with_graph)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
